{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uW9H2kN7p2TR"
   },
   "source": [
    "# Train OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f9NcpYap2TT"
   },
   "source": [
    "For train datasets please download last version of ocr datasets [https://nomeroff.net.ua/datasets/](https://nomeroff.net.ua/datasets/). Unpack archive and rename to **./datasets/ocr** .\n",
    "For examle\n",
    "```bash\n",
    "cd ./datasets/ocr\n",
    "wget https://nomeroff.net.ua/datasets/autoriaNumberplateOcrRu-2019-03-06.zip\n",
    "unzip autoriaNumberplateOcrRu-2019-03-06.zip\n",
    "mv autoriaNumberplateOcrRu-2019-03-06 ru\n",
    "```\n",
    "or use your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTfYW3Dvxv6e",
    "outputId": "27d461df-6d37-4dda-be05-8dcc640c64a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlJ1VST30sQU",
    "outputId": "9a618c17-3b6a-4f65-a573-a5c0c659c6be"
   },
   "outputs": [],
   "source": [
    "!unzip '/content/gdrive/My Drive/autoriaNumberplateOcrRu-2020-10-12.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUXYepCNAOcV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oy20guqIoTFo"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from fastai.vision import Path\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import albumentations as A\n",
    "#from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGUnu6lHAz-j"
   },
   "outputs": [],
   "source": [
    "train_path = '/content/autoriaNumberplateOcrRu-2020-10-12/train/img/'\n",
    "test_path = '/content/autoriaNumberplateOcrRu-2020-10-12/test/img/'\n",
    "val_path = '/content/autoriaNumberplateOcrRu-2020-10-12/val/img/'\n",
    "\n",
    "label_train_path = '/content/autoriaNumberplateOcrRu-2020-10-12/train/train_json.json'\n",
    "label_test_path = '/content/autoriaNumberplateOcrRu-2020-10-12/test/test_json.json'\n",
    "label_val_path = '/content/autoriaNumberplateOcrRu-2020-10-12/val/val_json.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyzuT84okPSo"
   },
   "outputs": [],
   "source": [
    "train_files = os.listdir(train_path)\n",
    "test_files = os.listdir(test_path)\n",
    "val_files = os.listdir(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8vMO4DzuJ86"
   },
   "outputs": [],
   "source": [
    "def create_label_json(json_name, label_path):\n",
    "  label_files = os.listdir(label_path)\n",
    "  list_json = []\n",
    "\n",
    "  for json_file in label_files:\n",
    "    with open(label_path + json_file) as json_file:\n",
    "      json_file=json.load(json_file)\n",
    "      img_name=json_file['name']\n",
    "      predicted=json_file['description']\n",
    "      dict_json={'img_name':img_name, 'predicted':predicted}\n",
    "      list_json.append(dict_json)\n",
    "      \n",
    "  with open(json_name,'w') as label_json:\n",
    "    json.dump(list_json, label_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nw43Ps0dyQmm"
   },
   "source": [
    "Forming json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEzj6k6LVrpZ"
   },
   "outputs": [],
   "source": [
    "label_train_path = '/content/autoriaNumberplateOcrRu-2020-10-12/train/ann/'\n",
    "label_test_path = '/content/autoriaNumberplateOcrRu-2020-10-12/test/ann/'\n",
    "label_val_path = '/content/autoriaNumberplateOcrRu-2020-10-12/val/ann/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ax5NtAbxykE"
   },
   "outputs": [],
   "source": [
    "create_label_json('val_json.json', label_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af8CahSTnG21"
   },
   "outputs": [],
   "source": [
    "!mv '/content/test_json.json' '/content/autoriaNumberplateOcrRu-2020-10-12/test/'\n",
    "!mv '/content/train_json.json' '/content/autoriaNumberplateOcrRu-2020-10-12/train/'\n",
    "!mv '/content/val_json.json' '/content/autoriaNumberplateOcrRu-2020-10-12/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFnPNoJWM7_J"
   },
   "outputs": [],
   "source": [
    "ALPHABET = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"E\", \"H\", \"K\", \"M\", \"O\", \"P\", \"T\", \"X\", \"Y\",'_']\n",
    "MAX_NOMER = 9\n",
    "LENGTH_ALPHABET = len(ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pCFFjt7nMld"
   },
   "outputs": [],
   "source": [
    "def encode(a):\n",
    "    label_oh = []\n",
    "    for i, char in enumerate(a):\n",
    "      onehot = [0]*LENGTH_ALPHABET\n",
    "      idx = ALPHABET.index(char)\n",
    "      onehot[idx] += 1\n",
    "      label_oh += onehot\n",
    "\n",
    "    # empty space replace  \n",
    "    while i != MAX_NOMER-1:\n",
    "      onehot = [0]*LENGTH_ALPHABET\n",
    "      idx = ALPHABET.index('_')\n",
    "      onehot[idx] += 1\n",
    "      label_oh += onehot\n",
    "      i+=1\n",
    "\n",
    "    return label_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od_pBVT-pd3q"
   },
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self, images_path, label_path, is_train=True, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.label_path = label_path\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        with open(label_path, 'r') as json_file:\n",
    "          labels = json.load(json_file)\n",
    "\n",
    "        self.list_img_names = [label['img_name'] for label in labels]\n",
    "        self.list_labels = [label['predicted'] for label in labels]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.list_img_names[idx]\n",
    "        image_path = self.images_path + img_name + '.png'\n",
    "        #img = cv2.imread(image_path,0)\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        label = self.list_labels[idx]\n",
    "        label_oh = encode(label)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=np.array(img))['image']\n",
    "            img = img/255\n",
    "            #img = self.transform(img)\n",
    "            #img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
    "            img = torch.tensor(img, dtype=torch.float)\n",
    "        return img.unsqueeze(dim=0), np.array(label_oh), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.list_img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHXqDaHGKr63"
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "        A.Resize(224, 224,interpolation=cv2.INTER_LINEAR),\n",
    "        A.Cutout(num_holes=10),\n",
    "        A.ElasticTransform(alpha_affine=2.5,p=)\n",
    "\n",
    "\n",
    "       # A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ka9CqFTWkzMz"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgCGiuzGk6ra"
   },
   "outputs": [],
   "source": [
    "train_ds = Mydataset(train_path, label_train_path, transform=transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0je16UefhG_",
    "outputId": "3df76561-4cc1-419f-ecef-6cf1fee1d5a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0784, 0.0784, 0.0784,  ..., 0.0706, 0.0706, 0.0706],\n",
       "          [0.0784, 0.0784, 0.0784,  ..., 0.0706, 0.0706, 0.0706],\n",
       "          [0.0745, 0.0784, 0.0784,  ..., 0.0706, 0.0706, 0.0706],\n",
       "          ...,\n",
       "          [0.2118, 0.2118, 0.2039,  ..., 0.1255, 0.1490, 0.1647],\n",
       "          [0.2118, 0.2118, 0.2039,  ..., 0.1255, 0.1490, 0.1647],\n",
       "          [0.2118, 0.2118, 0.2039,  ..., 0.1255, 0.1490, 0.1647]]]),\n",
       " array([0, 0, 0, 0, ..., 0, 0, 0, 0]),\n",
       " 'A906EY122')"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8EBZfEr9jCsd",
    "outputId": "6efd8d76-55b0-4aaf-b4ff-7298df3eb65a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 224])"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pil[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcNKwd2je7w7",
    "outputId": "93ac39d5-6895-4dcf-a9d5-c25cc048cacf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 224])"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[5][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRdF09A3peJB"
   },
   "outputs": [],
   "source": [
    "test_ds = Mydataset(test_path, label_test_path, False, transform)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo90XccOpoj0",
    "outputId": "e2c747f7-9c23-4d7a-fbe9-f0de9a8187ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=207, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.fc = nn.Linear(in_features=512, out_features=LENGTH_ALPHABET*MAX_NOMER, bias=True)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sQ-6KYoponK"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "optm = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7s_py-ZwSfx"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BUkgVYkpoqy",
    "outputId": "b357d58a-6732-4c9c-ec7d-7a1cfd59ad6b"
   },
   "outputs": [],
   "source": [
    "for epoch in range(6):\n",
    "    for step, i in enumerate(train_dl):\n",
    "        img, label_oh, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.float()).cuda()\n",
    "        pred = model(img)\n",
    "        loss = loss_func(pred, label_oh)\n",
    "        optm.zero_grad()\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "        print('eopch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIwcqTHCsmTw"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1Fko8pcpeMr"
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "owZf97NAPOk9",
    "outputId": "da4066cb-67f7-4cf5-b641-7a51f98f8c49"
   },
   "outputs": [],
   "source": [
    "true_label = 0\n",
    "for step, (img, label_oh, label) in enumerate(test_dl):\n",
    "    img = Variable(img).cuda()\n",
    "    pred = model(img)\n",
    "\n",
    "    c0 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[0:LENGTH_ALPHABET])]\n",
    "    c1 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET:LENGTH_ALPHABET*2])]\n",
    "    c2 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*2:LENGTH_ALPHABET*3])]\n",
    "    c3 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*3:LENGTH_ALPHABET*4])]\n",
    "    c4 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*4:LENGTH_ALPHABET*5])]\n",
    "    c5 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*5:LENGTH_ALPHABET*6])]\n",
    "    c6 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*6:LENGTH_ALPHABET*7])]\n",
    "    c7 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*7:LENGTH_ALPHABET*8])]\n",
    "    c8 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*8:LENGTH_ALPHABET*9])]\n",
    "\n",
    "    c = '%s%s%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6, c7, c8)\n",
    "    c =  c.replace('_','')\n",
    "    if label[0] == c:\n",
    "      true_label+=1\n",
    "      print( true_label, ' / ', step)\n",
    "      print( 'pred',c ,'real',label[0])\n",
    "    else:\n",
    "      print('\\nОШИБКА = ','pred',c ,'real',label[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNAV24MZrCiT",
    "outputId": "d9acd05b-69ed-492a-9b5e-e8804fbdee97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793861360384966"
      ]
     },
     "execution_count": 238,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30122/30756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nmd8ewmMrQp-"
   },
   "outputs": [],
   "source": [
    "ALPHABET = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"E\", \"H\", \"K\", \"M\", \"O\", \"P\", \"T\", \"X\", \"Y\",'_']\n",
    "MAX_NOMER = 9\n",
    "LENGTH_ALPHABET = len(ALPHABET)\n",
    "PATH = '/content/model_dump_6_epoch.pth'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "def predict_img(img_path):\n",
    "  img = Image.open(img_path)\n",
    "  img = img.convert('L')\n",
    "  img = transform(img)\n",
    "  img = Variable(img).cuda()\n",
    "  img = img.unsqueeze(dim=1)\n",
    "  pred = model(img)\n",
    "\n",
    "  c0 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[0:LENGTH_ALPHABET])]\n",
    "  c1 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET:LENGTH_ALPHABET*2])]\n",
    "  c2 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*2:LENGTH_ALPHABET*3])]\n",
    "  c3 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*3:LENGTH_ALPHABET*4])]\n",
    "  c4 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*4:LENGTH_ALPHABET*5])]\n",
    "  c5 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*5:LENGTH_ALPHABET*6])]\n",
    "  c6 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*6:LENGTH_ALPHABET*7])]\n",
    "  c7 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*7:LENGTH_ALPHABET*8])]\n",
    "  c8 = ALPHABET[np.argmax(pred.squeeze().cpu().tolist()[LENGTH_ALPHABET*8:LENGTH_ALPHABET*9])]\n",
    "\n",
    "  c = '%s%s%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6, c7, c8)\n",
    "  c =  c.replace('_','')\n",
    "\n",
    "  return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "NZva9d5SrRRA",
    "outputId": "88021a1a-989a-4c22-d711-cfd281fb4840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 ms, sys: 0 ns, total: 11.4 ms\n",
      "Wall time: 11.3 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'A001BP54'"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predict_img('/content/autoriaNumberplateOcrRu-2020-10-12/test/img/A001BP54.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"ocr-ru.ipynb\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
